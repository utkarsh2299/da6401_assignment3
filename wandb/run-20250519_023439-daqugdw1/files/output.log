[34m[1mwandb[0m: [33mWARNING[0m Ignoring project 'da6401_assignment3' when running a sweep.
Created dataloaders - Train: 44201 samples, Dev: 4358 samples, Test: 4502 samples
The model has 3,936,339 trainable parameters
                                                                                                                                                            
Epoch: 01 | Time: 0.0m 11.62s
	Train Loss: 2.944
	Val. Loss: 2.396
	Train Acc: 0.349 | Val. Acc: 0.371 (sample)
	Best validation loss: 2.396
Epoch: 02 | Time: 0.0m 12.08s
	Train Loss: 2.140
	Val. Loss: 1.708
	Train Acc: 0.490 | Val. Acc: 0.485 (sample)
	Best validation loss: 1.708
Epoch: 03 | Time: 0.0m 12.00s
	Train Loss: 1.650
	Val. Loss: 1.398
	Train Acc: 0.550 | Val. Acc: 0.554 (sample)
	Best validation loss: 1.398
Epoch: 04 | Time: 0.0m 11.38s
	Train Loss: 1.392
	Val. Loss: 1.277
	Train Acc: 0.627 | Val. Acc: 0.614 (sample)
	Best validation loss: 1.277
Epoch: 05 | Time: 0.0m 11.57s
	Train Loss: 1.230
	Val. Loss: 1.193
	Train Acc: 0.653 | Val. Acc: 0.631 (sample)
	Best validation loss: 1.193
Epoch: 06 | Time: 0.0m 11.57s
	Train Loss: 1.125
	Val. Loss: 1.151
	Train Acc: 0.692 | Val. Acc: 0.663 (sample)
	Best validation loss: 1.151
Epoch: 07 | Time: 0.0m 11.84s
	Train Loss: 1.043
	Val. Loss: 1.140
	Train Acc: 0.702 | Val. Acc: 0.657 (sample)
	Best validation loss: 1.140
Epoch: 08 | Time: 0.0m 11.87s
	Train Loss: 0.973
	Val. Loss: 1.117
	Train Acc: 0.735 | Val. Acc: 0.673 (sample)
	Best validation loss: 1.117
Epoch: 09 | Time: 0.0m 11.50s
	Train Loss: 0.918
	Val. Loss: 1.087
	Train Acc: 0.747 | Val. Acc: 0.683 (sample)
	Best validation loss: 1.087
Epoch: 10 | Time: 0.0m 11.16s
	Train Loss: 0.872
	Val. Loss: 1.077
	Train Acc: 0.751 | Val. Acc: 0.703 (sample)
	Best validation loss: 1.077
Epoch: 11 | Time: 0.0m 11.61s
	Train Loss: 0.830
	Val. Loss: 1.055
	Train Acc: 0.758 | Val. Acc: 0.706 (sample)
	Best validation loss: 1.055
Epoch: 12 | Time: 0.0m 11.51s
	Train Loss: 0.792
	Val. Loss: 1.044
	Train Acc: 0.794 | Val. Acc: 0.721 (sample)
	Best validation loss: 1.044
Epoch: 13 | Time: 0.0m 10.83s
	Train Loss: 0.762
	Val. Loss: 1.020
	Train Acc: 0.798 | Val. Acc: 0.723 (sample)
	Best validation loss: 1.020
Epoch: 14 | Time: 0.0m 11.52s
	Train Loss: 0.728
	Val. Loss: 1.023
	Train Acc: 0.805 | Val. Acc: 0.707 (sample)
	No improvement in validation loss for 1 epochs
Epoch: 15 | Time: 0.0m 11.75s
	Train Loss: 0.702
	Val. Loss: 1.031
	Train Acc: 0.815 | Val. Acc: 0.729 (sample)
	No improvement in validation loss for 2 epochs
Epoch: 16 | Time: 0.0m 11.33s
	Train Loss: 0.675
	Val. Loss: 1.031
	Train Acc: 0.836 | Val. Acc: 0.725 (sample)
	No improvement in validation loss for 3 epochs
Epoch: 17 | Time: 0.0m 11.65s
	Train Loss: 0.645
	Val. Loss: 1.021
	Train Acc: 0.813 | Val. Acc: 0.723 (sample)
	No improvement in validation loss for 4 epochs
Epoch: 18 | Time: 0.0m 11.92s
	Train Loss: 0.632
	Val. Loss: 1.006
	Train Acc: 0.829 | Val. Acc: 0.733 (sample)
	Best validation loss: 1.006
Epoch: 19 | Time: 0.0m 11.44s
	Train Loss: 0.609
	Val. Loss: 1.025
	Train Acc: 0.847 | Val. Acc: 0.726 (sample)
	No improvement in validation loss for 1 epochs
Epoch: 20 | Time: 0.0m 11.84s
	Train Loss: 0.587
	Val. Loss: 1.045
	Train Acc: 0.841 | Val. Acc: 0.723 (sample)
	No improvement in validation loss for 2 epochs
Test Accuracy: 0.3621
Sample 1:
Source: ank
Prediction: ‡§Ö‡§Ç‡§ï
Target: ‡§Ö‡§Ç‡§ï
Correct: Yes
--------------------------------------------------
Sample 2:
Source: anka
Prediction: ‡§Ö‡§Ç‡§ï‡§æ
Target: ‡§Ö‡§Ç‡§ï
Correct: No
--------------------------------------------------
Sample 3:
Source: ankit
Prediction: ‡§Ö‡§®‡§ï‡•Ä‡§§
Target: ‡§Ö‡§Ç‡§ï‡§ø‡§§
Correct: No
--------------------------------------------------
Sample 4:
Source: anakon
Prediction: ‡§Ö‡§®‡§æ‡§ï‡•ã‡§Ç
Target: ‡§Ö‡§Ç‡§ï‡•ã‡§Ç
Correct: No
--------------------------------------------------
Sample 5:
Source: ankhon
Prediction: ‡§Ö‡§Ç‡§ñ‡•ã‡§Ç
Target: ‡§Ö‡§Ç‡§ï‡•ã‡§Ç
Correct: No
--------------------------------------------------
Sample 6:
Source: ankon
Prediction: ‡§Ö‡§®‡§ï‡•ã‡§Ç
Target: ‡§Ö‡§Ç‡§ï‡•ã‡§Ç
Correct: No
--------------------------------------------------
Sample 7:
Source: angkor
Prediction: ‡§Ö‡§Ç‡§ó‡§ï‡§∞
Target: ‡§Ö‡§Ç‡§ï‡•ã‡§∞
Correct: No
--------------------------------------------------
Sample 8:
Source: ankor
Prediction: ‡§è‡§Ç‡§ï‡•ã‡§∞
Target: ‡§Ö‡§Ç‡§ï‡•ã‡§∞
Correct: No
--------------------------------------------------
Sample 9:
Source: angaarak
Prediction: ‡§Ö‡§Ç‡§ó‡§æ‡§∞‡§ï
Target: ‡§Ö‡§Ç‡§ó‡§æ‡§∞‡§ï
Correct: Yes
--------------------------------------------------
Sample 10:
Source: angarak
Prediction: ‡§Ö‡§Ç‡§ó‡§∞‡§æ‡§ï
Target: ‡§Ö‡§Ç‡§ó‡§æ‡§∞‡§ï
Correct: No
--------------------------------------------------
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
Using uniform attention weights (model may not have attention)
  plt.tight_layout()
/speech/utkarsh/da6401_assignment3/utils.py:224: UserWarning: Glyph 8594 (\N{RIGHTWARDS ARROW}) missing from font(s) Nirmala UI.
  plt.savefig(save_path, dpi=300, bbox_inches='tight')
Attention heatmaps saved to: attention_heatmaps.png
