2025-05-18 20:59:08,280 INFO    Thread-7 (_run_job):966699 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250518_205908-bjtt7ygy/logs/debug.log
2025-05-18 20:59:08,280 INFO    Thread-7 (_run_job):966699 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250518_205908-bjtt7ygy/logs/debug-internal.log
2025-05-18 20:59:08,280 INFO    Thread-7 (_run_job):966699 [wandb_init.py:init():781] calling init triggers
2025-05-18 20:59:08,280 INFO    Thread-7 (_run_job):966699 [wandb_init.py:init():786] wandb.init called with sweep_config: {'batch_size': 128, 'beam_size': 3, 'cell_type': 'gru', 'decoder_dropout': 0.3, 'embedding_size': 16, 'encoder_dropout': 0.5, 'hidden_size': 256, 'learning_rate': 0.0005, 'num_layers': 3, 'use_attention': True}
config: {'data_path': 'dakshina_dataset_v1.0/hi/lexicons/', 'embedding_size': 16, 'hidden_size': 256, 'num_encoder_layers': 3, 'num_decoder_layers': 3, 'encoder_dropout': 0.5, 'decoder_dropout': 0.3, 'cell_type': 'gru', 'batch_size': 128, 'learning_rate': 0.0005, 'n_epochs': 20, 'clip': 1.0, 'teacher_forcing_ratio': 0.5, 'patience': 5, 'min_delta': 0.0, 'beam_size': 3, 'save_path': 'models/', 'model_name': 'best_model.pt', 'seed': 42, 'log_wandb': True, 'wandb_project': 'da6401_assignment3', 'wandb_name': 'gru-ec_3-dc_3-hs_256-emb_16-bs_128-lr_0.0005', 'use_attention': False, '_wandb': {}}
2025-05-18 20:59:08,280 INFO    Thread-7 (_run_job):966699 [wandb_init.py:init():801] wandb.init() called while a run is active
2025-05-18 21:03:43,897 INFO    Thread-7 (_run_job):966699 [wandb_run.py:_finish():2189] finishing run da24s011-indian-institute-of-technology-madras/da6401_assignment3/bjtt7ygy
2025-05-18 21:03:43,898 INFO    Thread-7 (_run_job):966699 [wandb_run.py:_atexit_cleanup():2419] got exitcode: 1
2025-05-18 21:03:43,898 INFO    Thread-7 (_run_job):966699 [wandb_run.py:_restore():2401] restore
2025-05-18 21:03:43,898 INFO    Thread-7 (_run_job):966699 [wandb_run.py:_restore():2407] restore done
2025-05-18 21:03:46,392 INFO    Thread-7 (_run_job):966699 [wandb_run.py:_footer_history_summary_info():4064] rendering history
2025-05-18 21:03:46,393 INFO    Thread-7 (_run_job):966699 [wandb_run.py:_footer_history_summary_info():4096] rendering summary
2025-05-18 21:03:46,393 INFO    Thread-7 (_run_job):966699 [wandb_run.py:_footer_sync_info():4025] logging synced files
2025-05-18 21:03:46,396 ERROR   MainThread:966699 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run bjtt7ygy errored:
Traceback (most recent call last):
  File "/speech/utkarsh/.local/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/speech/utkarsh/da6401_assignment3/sweep.py", line 50, in sweep_train
    main(model_config)
  File "/speech/utkarsh/da6401_assignment3/main.py", line 100, in main
    model.load_state_dict(torch.load(model_save_path))
  File "/speech/utkarsh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1497, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for Seq2Seq:
	Missing key(s) in state_dict: "encoder.rnn.weight_ih_l2", "encoder.rnn.weight_hh_l2", "encoder.rnn.bias_ih_l2", "encoder.rnn.bias_hh_l2", "encoder.rnn.weight_ih_l2_reverse", "encoder.rnn.weight_hh_l2_reverse", "encoder.rnn.bias_ih_l2_reverse", "encoder.rnn.bias_hh_l2_reverse", "decoder.rnn.weight_ih_l2", "decoder.rnn.weight_hh_l2", "decoder.rnn.bias_ih_l2", "decoder.rnn.bias_hh_l2". 
	size mismatch for encoder.embedding.weight: copying a param with shape torch.Size([30, 128]) from checkpoint, the shape in current model is torch.Size([30, 16]).
	size mismatch for encoder.rnn.weight_ih_l0: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([768, 16]).
	size mismatch for encoder.rnn.weight_hh_l0: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for encoder.rnn.bias_ih_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.rnn.bias_hh_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.rnn.weight_ih_l0_reverse: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([768, 16]).
	size mismatch for encoder.rnn.weight_hh_l0_reverse: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for encoder.rnn.bias_ih_l0_reverse: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.rnn.bias_hh_l0_reverse: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.rnn.weight_ih_l1: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([768, 512]).
	size mismatch for encoder.rnn.weight_hh_l1: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for encoder.rnn.bias_ih_l1: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.rnn.bias_hh_l1: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.rnn.weight_ih_l1_reverse: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([768, 512]).
	size mismatch for encoder.rnn.weight_hh_l1_reverse: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for encoder.rnn.bias_ih_l1_reverse: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.rnn.bias_hh_l1_reverse: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for encoder.fc.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([256, 512]).
	size mismatch for encoder.fc.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for decoder.embedding.weight: copying a param with shape torch.Size([67, 128]) from checkpoint, the shape in current model is torch.Size([67, 16]).
	size mismatch for decoder.rnn.weight_ih_l0: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([768, 16]).
	size mismatch for decoder.rnn.weight_hh_l0: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for decoder.rnn.bias_ih_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for decoder.rnn.bias_hh_l0: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for decoder.rnn.weight_ih_l1: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for decoder.rnn.weight_hh_l1: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([768, 256]).
	size mismatch for decoder.rnn.bias_ih_l1: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for decoder.rnn.bias_hh_l1: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for decoder.fc_out.weight: copying a param with shape torch.Size([67, 64]) from checkpoint, the shape in current model is torch.Size([67, 256]).

2025-05-18 21:03:57,404 INFO    MsgRouterThr:966699 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-05-18 21:19:10,105 ERROR   MainThread:966699 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run mv0w9m5l errored:
Traceback (most recent call last):
  File "/speech/utkarsh/.local/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/speech/utkarsh/da6401_assignment3/sweep.py", line 50, in sweep_train
    main(model_config)
  File "/speech/utkarsh/da6401_assignment3/main.py", line 124, in main
    examples = visualize_attention(
  File "/speech/utkarsh/da6401_assignment3/utils.py", line 177, in visualize_attention
    output_indices, attention_weights = model.greedy_decode(src_tensor, max_len=100)
ValueError: too many values to unpack (expected 2)

2025-05-18 21:19:14,106 INFO    MsgRouterThr:966699 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-05-18 21:31:40,269 ERROR   MainThread:966699 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run qkaxbcbr errored:
Traceback (most recent call last):
  File "/speech/utkarsh/.local/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/speech/utkarsh/da6401_assignment3/sweep.py", line 50, in sweep_train
    main(model_config)
  File "/speech/utkarsh/da6401_assignment3/main.py", line 124, in main
    examples = visualize_attention(
  File "/speech/utkarsh/da6401_assignment3/utils.py", line 177, in visualize_attention
    output_indices, attention_weights = model.greedy_decode(src_tensor, max_len=100)
ValueError: too many values to unpack (expected 2)

2025-05-18 21:31:43,267 INFO    MsgRouterThr:966699 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-05-18 21:41:49,118 ERROR   MainThread:966699 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run hz7jqvxl errored:
Traceback (most recent call last):
  File "/speech/utkarsh/.local/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/speech/utkarsh/da6401_assignment3/sweep.py", line 50, in sweep_train
    main(model_config)
  File "/speech/utkarsh/da6401_assignment3/main.py", line 124, in main
    examples = visualize_attention(
  File "/speech/utkarsh/da6401_assignment3/utils.py", line 177, in visualize_attention
    output_indices, attention_weights = model.greedy_decode(src_tensor, max_len=100)
ValueError: too many values to unpack (expected 2)

2025-05-18 21:41:54,120 INFO    MsgRouterThr:966699 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-05-18 21:46:05,732 ERROR   MainThread:966699 [pyagent.py:_run_jobs_from_queue():234] [no run ID] Run lpffrman errored:
Traceback (most recent call last):
  File "/speech/utkarsh/.local/lib/python3.10/site-packages/wandb/agents/pyagent.py", line 306, in _run_job
    self._function()
  File "/speech/utkarsh/da6401_assignment3/sweep.py", line 50, in sweep_train
    main(model_config)
  File "/speech/utkarsh/da6401_assignment3/main.py", line 100, in main
    model.load_state_dict(torch.load(model_save_path))
  File "/speech/utkarsh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1497, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for Seq2Seq:
	size mismatch for encoder.rnn.weight_ih_l0: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.weight_hh_l0: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.bias_ih_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.bias_hh_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.weight_ih_l0_reverse: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.weight_hh_l0_reverse: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.bias_ih_l0_reverse: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.bias_hh_l0_reverse: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.weight_ih_l1: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).
	size mismatch for encoder.rnn.weight_hh_l1: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.bias_ih_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.bias_hh_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.weight_ih_l1_reverse: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).
	size mismatch for encoder.rnn.weight_hh_l1_reverse: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.bias_ih_l1_reverse: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.bias_hh_l1_reverse: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.weight_ih_l2: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).
	size mismatch for encoder.rnn.weight_hh_l2: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.bias_ih_l2: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.bias_hh_l2: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.weight_ih_l2_reverse: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([1024, 512]).
	size mismatch for encoder.rnn.weight_hh_l2_reverse: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for encoder.rnn.bias_ih_l2_reverse: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.rnn.bias_hh_l2_reverse: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for encoder.fc.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([256, 512]).
	size mismatch for encoder.fc.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for decoder.rnn.weight_ih_l0: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for decoder.rnn.weight_hh_l0: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for decoder.rnn.bias_ih_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for decoder.rnn.bias_hh_l0: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for decoder.rnn.weight_ih_l1: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for decoder.rnn.weight_hh_l1: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for decoder.rnn.bias_ih_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for decoder.rnn.bias_hh_l1: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for decoder.rnn.weight_ih_l2: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for decoder.rnn.weight_hh_l2: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([1024, 256]).
	size mismatch for decoder.rnn.bias_ih_l2: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for decoder.rnn.bias_hh_l2: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for decoder.fc_out.weight: copying a param with shape torch.Size([67, 128]) from checkpoint, the shape in current model is torch.Size([67, 256]).

2025-05-18 21:46:05,734 ERROR   MainThread:966699 [pyagent.py:_run_jobs_from_queue():259] [no run ID] Detected 5 failed runs in a row at start, killing sweep.
2025-05-18 21:46:06,731 INFO    MsgRouterThr:966699 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
