2025-05-18 23:07:17,940 INFO    Thread-7 (_run_job):1011658 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250518_230717-md76ksr5/logs/debug.log
2025-05-18 23:07:17,940 INFO    Thread-7 (_run_job):1011658 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250518_230717-md76ksr5/logs/debug-internal.log
2025-05-18 23:07:17,940 INFO    Thread-7 (_run_job):1011658 [wandb_init.py:init():781] calling init triggers
2025-05-18 23:07:17,940 INFO    Thread-7 (_run_job):1011658 [wandb_init.py:init():786] wandb.init called with sweep_config: {'batch_size': 64, 'beam_size': None, 'cell_type': 'lstm', 'decoder_dropout': 0.2, 'embedding_size': 128, 'encoder_dropout': 0.5, 'hidden_size': 64, 'learning_rate': 0.0005, 'num_layers': 1, 'use_attention': True}
config: {'data_path': 'dakshina_dataset_v1.0/hi/lexicons/', 'embedding_size': 128, 'hidden_size': 64, 'num_encoder_layers': 1, 'num_decoder_layers': 1, 'encoder_dropout': 0.5, 'decoder_dropout': 0.2, 'cell_type': 'lstm', 'batch_size': 64, 'learning_rate': 0.0005, 'n_epochs': 20, 'clip': 1.0, 'teacher_forcing_ratio': 0.5, 'patience': 5, 'min_delta': 0.0, 'beam_size': None, 'save_path': 'models_true/', 'model_name': 'best_model.pt', 'seed': 42, 'log_wandb': True, 'wandb_project': 'da6401_assignment3', 'wandb_name': 'lstm-ec_1-dc_1-hs_64-emb_128-bs_64-lr_0.0005', 'use_attention': False, '_wandb': {}}
2025-05-18 23:07:17,940 INFO    Thread-7 (_run_job):1011658 [wandb_init.py:init():801] wandb.init() called while a run is active
