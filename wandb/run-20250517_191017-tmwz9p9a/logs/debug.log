2025-05-17 19:10:17,455 INFO    Thread-13 (_run_job):788773 [wandb_setup.py:_flush():67] Current SDK version is 0.19.9
2025-05-17 19:10:17,455 INFO    Thread-13 (_run_job):788773 [wandb_setup.py:_flush():67] Configure stats pid to 788773
2025-05-17 19:10:17,455 INFO    Thread-13 (_run_job):788773 [wandb_setup.py:_flush():67] Loading settings from /speech/utkarsh/.config/wandb/settings
2025-05-17 19:10:17,455 INFO    Thread-13 (_run_job):788773 [wandb_setup.py:_flush():67] Loading settings from /speech/utkarsh/da6401_assignment3/wandb/settings
2025-05-17 19:10:17,455 INFO    Thread-13 (_run_job):788773 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-05-17 19:10:17,455 INFO    Thread-13 (_run_job):788773 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250517_191017-tmwz9p9a/logs/debug.log
2025-05-17 19:10:17,455 INFO    Thread-13 (_run_job):788773 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250517_191017-tmwz9p9a/logs/debug-internal.log
2025-05-17 19:10:17,456 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():781] calling init triggers
2025-05-17 19:10:17,456 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():786] wandb.init called with sweep_config: {'batch_size': 32, 'beam_size': None, 'cell_type': 'lstm', 'decoder_dropout': 0.2, 'embedding_size': 16, 'encoder_dropout': 0.2, 'hidden_size': 256, 'learning_rate': 0.001, 'num_layers': 3}
config: {'_wandb': {}}
2025-05-17 19:10:17,456 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():809] starting backend
2025-05-17 19:10:17,456 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():813] sending inform_init request
2025-05-17 19:10:17,458 INFO    Thread-13 (_run_job):788773 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-05-17 19:10:17,458 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():823] backend started and connected
2025-05-17 19:10:17,459 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_config_callback():1327] config_cb None None {'batch_size': 32, 'beam_size': None, 'cell_type': 'lstm', 'decoder_dropout': 0.2, 'embedding_size': 16, 'encoder_dropout': 0.2, 'hidden_size': 256, 'learning_rate': 0.001, 'num_layers': 3}
2025-05-17 19:10:17,461 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():915] updated telemetry
2025-05-17 19:10:17,469 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():939] communicating run to backend with 90.0 second timeout
2025-05-17 19:10:18,158 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():1014] starting run threads in backend
2025-05-17 19:10:18,345 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_console_start():2454] atexit reg
2025-05-17 19:10:18,345 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-05-17 19:10:18,345 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_redirect():2371] Wrapping output streams.
2025-05-17 19:10:18,346 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_redirect():2394] Redirects installed.
2025-05-17 19:10:18,346 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():1056] run started, returning control to user process
2025-05-17 19:10:18,348 INFO    Thread-13 (_run_job):788773 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250517_191018-tmwz9p9a/logs/debug.log
2025-05-17 19:10:18,349 INFO    Thread-13 (_run_job):788773 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /speech/utkarsh/da6401_assignment3/wandb/run-20250517_191018-tmwz9p9a/logs/debug-internal.log
2025-05-17 19:10:18,349 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():781] calling init triggers
2025-05-17 19:10:18,349 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():786] wandb.init called with sweep_config: {'batch_size': 32, 'beam_size': None, 'cell_type': 'lstm', 'decoder_dropout': 0.2, 'embedding_size': 16, 'encoder_dropout': 0.2, 'hidden_size': 256, 'learning_rate': 0.001, 'num_layers': 3}
config: {'data_path': 'dakshina_dataset_v1.0/hi/lexicons/', 'embedding_size': 16, 'hidden_size': 256, 'num_encoder_layers': 3, 'num_decoder_layers': 3, 'encoder_dropout': 0.2, 'decoder_dropout': 0.2, 'cell_type': 'lstm', 'batch_size': 32, 'learning_rate': 0.001, 'n_epochs': 20, 'clip': 1.0, 'teacher_forcing_ratio': 0.5, 'patience': 5, 'min_delta': 0.0, 'beam_size': None, 'save_path': 'models/', 'model_name': 'best_model.pt', 'seed': 42, 'log_wandb': True, 'wandb_project': 'da6401_assignment3', 'wandb_name': 'lstm-ec_3-dc_3-hs_256-emb_16-bs_32-lr_0.001', '_wandb': {}}
2025-05-17 19:10:18,349 INFO    Thread-13 (_run_job):788773 [wandb_init.py:init():801] wandb.init() called while a run is active
2025-05-17 19:26:15,969 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_finish():2189] finishing run da24s011-indian-institute-of-technology-madras/da6401_assignment3/tmwz9p9a
2025-05-17 19:26:15,970 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_atexit_cleanup():2419] got exitcode: 0
2025-05-17 19:26:15,970 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_restore():2401] restore
2025-05-17 19:26:15,970 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_restore():2407] restore done
2025-05-17 19:26:17,666 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_footer_history_summary_info():4064] rendering history
2025-05-17 19:26:17,667 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_footer_history_summary_info():4096] rendering summary
2025-05-17 19:26:17,667 INFO    Thread-13 (_run_job):788773 [wandb_run.py:_footer_sync_info():4025] logging synced files
